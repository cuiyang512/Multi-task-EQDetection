{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0d2976-fbe2-41f0-87cc-d837065fae66",
   "metadata": {},
   "source": [
    "## Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80b1cbb8-afdc-43bf-b23c-5ec538fd8317",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 15:56:42.461384: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-11-02 15:56:42.461406: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/g202321530/anaconda3/envs/eqcct/lib/python3.7/site-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "\n",
    "import tensorflow.compat.v1 as tf1\n",
    "tf1.disable_v2_behavior()\n",
    "\n",
    "import os\n",
    "os.environ['KERAS_BACKEND']='tensorflow'\n",
    "\n",
    "from keras.models import load_model\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "from scipy.signal import butter, lfilter, lfilter_zi\n",
    "import matplotlib\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "matplotlib.use('agg')\n",
    "import pandas as pd\n",
    "import math\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "from os import listdir\n",
    "import platform\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta\n",
    "import contextlib\n",
    "import sys\n",
    "import warnings\n",
    "from scipy import signal\n",
    "from matplotlib.lines import Line2D\n",
    "from obspy import read\n",
    "from os.path import join\n",
    "import json\n",
    "import pickle\n",
    "import faulthandler; faulthandler.enable()\n",
    "import obspy\n",
    "import logging\n",
    "from obspy.signal.trigger import trigger_onset\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, log_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from glob import glob\n",
    "from sklearn.utils import class_weight\n",
    "from numpy.random import seed\n",
    "from tensorflow.keras.regularizers import l2\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from tensorflow.python.util import deprecation\n",
    "deprecation._PRINT_DEPRECATION_WARNINGS = False\n",
    "\n",
    "from eqcct_dependence_p import *\n",
    "from eqcct_dependence_s import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "462904ac",
   "metadata": {},
   "source": [
    "## Hyperparameter setup for EQCCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d1f32f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1 = 6000\n",
    "w2 = 3\n",
    "drop_rate = 0.2\n",
    "stochastic_depth_rate = 0.1\n",
    "\n",
    "positional_emb = False\n",
    "conv_layers = 4\n",
    "num_classes = 1\n",
    "input_shape = (w1, w2)\n",
    "num_classes = 1\n",
    "input_shape = (6000, 3)\n",
    "image_size = 6000  \n",
    "patch_size = 40  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size)\n",
    "projection_dim = 40\n",
    "\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4980ea96",
   "metadata": {},
   "source": [
    "## Retrained EQCCT for P-wave arrival prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2069149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-02 15:56:45.006009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-02 15:56:45.006264: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2024-11-02 15:56:45.006481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2024-11-02 15:56:45.006528: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory\n",
      "2024-11-02 15:56:45.006570: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory\n",
      "2024-11-02 15:56:45.006611: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory\n",
      "2024-11-02 15:56:45.038789: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory\n",
      "2024-11-02 15:56:45.038843: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2024-11-02 15:56:45.038852: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2024-11-02 15:56:45.039288: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading is complete!\n",
      "Testing ...\n",
      "Writting results into: \" test_pwave_retrain_outputs \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 15/15 [02:44<00:00, 10.95s/it]\n"
     ]
    }
   ],
   "source": [
    "test_pwave(input_hdf5= '/home/g202321530/Yang/Data/Earthquake_data/TXED/TXED_0913.h5', # here you need to change the input path of your own data\n",
    "       input_testset='./data/signalid_random_1.5w.npy',\n",
    "       #input_model='/home/g202321530/Yang/Yangtze/EQ_classification/Texas_1/txed-main/demos/EQCCT_P/test_trainer_outputs/models/test_trainer_001.h5',\n",
    "       input_model='./model/test_trainer_EQCCT_P_retrain.h5',\n",
    "       output_name='test_pwave_retrain',\n",
    "       detection_threshold=0.1,                \n",
    "       P_threshold=0.1,\n",
    "       number_of_plots=3,\n",
    "       estimate_uncertainty=True, \n",
    "       number_of_sampling=2,\n",
    "       input_dimention=(6000, 3),\n",
    "       normalization_mode='std',\n",
    "       mode='generator',\n",
    "       batch_size=1024,\n",
    "       gpuid=None,\n",
    "       gpu_limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f323f46",
   "metadata": {},
   "source": [
    "## Retrained EQCCT for S-wave arrival prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92d91880",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model ...\n",
      "Loading is complete!\n",
      "Testing ...\n",
      "Writting results into: \" test_swave_retrain_outputs \"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████| 15/15 [02:51<00:00, 11.45s/it]\n"
     ]
    }
   ],
   "source": [
    "test_swave(input_hdf5='/home/g202321530/Yang/Data/Earthquake_data/TXED/TXED_0913.h5', # here you need to change the input path of your own data\n",
    "       input_testset='./data/signalid_random_1.5w.npy',\n",
    "       input_model='./model/test_trainer_EQCCT_S_retrain.h5',\n",
    "       #input_model='./model/test_trainer_021.h5',\n",
    "       output_name='test_swave_retrain',\n",
    "       S_threshold=0.1, \n",
    "       number_of_plots=3,\n",
    "       estimate_uncertainty=True, \n",
    "       number_of_sampling=2,\n",
    "       input_dimention=(6000, 3),\n",
    "       normalization_mode='std',\n",
    "       mode='generator',\n",
    "       batch_size=1024,\n",
    "       gpuid=None,\n",
    "       gpu_limit=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27ac5a6-ff83-471f-8e3d-4adbc5c66500",
   "metadata": {},
   "source": [
    "## Define a band pass filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81d2e8fc-4cd3-4e3a-895b-cf9b837a29a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "\n",
    "def butter_bandpass_filter_zi(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    zi = lfilter_zi(b, a)\n",
    "    y,zo = lfilter(b, a, data, zi=zi*data[0])\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc43a3c6-8c28-4b3e-a7ed-a630bf17b592",
   "metadata": {},
   "source": [
    "## Load the 3-C signal waveforms and obtain the arrivals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b66b083e-f93b-4595-af71-a927ea1d01f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------arrival time calculation begin-------------------\n",
      "(15000,) [ 99 498  98 ... 898 598 598]\n",
      "(15000,) [ 616  709  382 ... 2003 2551 1035]\n",
      "-----------arrival time calculation end-------------------\n",
      "-----------signal format convert begin-------------------\n",
      "-----------signal format convert finihs-------------------\n",
      "(15000, 6000, 3)\n"
     ]
    }
   ],
   "source": [
    "# Load the TXED dataset\n",
    "# please down load the TXED from: https://drive.google.com/drive/folders/1WXVB8ytNB4bOaZ97oq6OmMRyAEg95trp?usp=sharing\n",
    "f = h5py.File(\"/home/g202321530/Yang/Data/Earthquake_data/TXED/TXED_0913.h5\", 'r')\n",
    "# Load randomly selected random id\n",
    "event_id = np.load('./data/signalid_random_1.5w.npy')\n",
    "\n",
    "\n",
    "# obtain the P- and S-wave arrivals\n",
    "P_arrival_list = []\n",
    "S_arrival_list = []\n",
    "print('-----------arrival time calculation begin-------------------')\n",
    "for key in event_id:\n",
    "    if key in f:   \n",
    "        dataset = f.get(key)\n",
    "        P_arrival_list.append(int(dataset.attrs['p_arrival_sample']))\n",
    "        S_arrival_list.append(int(dataset.attrs['s_arrival_sample']))\n",
    "P_arrival_list = np.array(P_arrival_list)\n",
    "S_arrival_list = np.array(S_arrival_list)\n",
    "P_phase_label = P_arrival_list\n",
    "S_phase_label = S_arrival_list\n",
    "\n",
    "print(P_arrival_list.shape, P_arrival_list)\n",
    "print(S_arrival_list.shape, S_arrival_list)\n",
    "print('-----------arrival time calculation end-------------------')\n",
    "\n",
    "# band-pass and normalization of the 3-C waveforms\n",
    "signal_list = []\n",
    "print('-----------signal format convert begin-------------------')\n",
    "for key in event_id:\n",
    "    if key in f:   \n",
    "        dataset = f.get(key)\n",
    "        datas = dataset['data']\n",
    "        datas = np.array(datas)\n",
    "        datas_0 = butter_bandpass_filter_zi(datas[:,0], 1, 45, 100, order=3)\n",
    "        datas_1 = butter_bandpass_filter_zi(datas[:,1], 1, 45, 100, order=3)\n",
    "        datas_2 = butter_bandpass_filter_zi(datas[:,2], 1, 45, 100, order=3)\n",
    "        datas = np.vstack([datas_0, datas_1, datas_2])\n",
    "        signal_list.append(datas) \n",
    "signal_values = np.array(signal_list)\n",
    "bp_signal= np.transpose(signal_values, [0, 2, 1])\n",
    "\n",
    "\n",
    "#Normalized trace-by-trace\n",
    "max_values_per_event = np.max(bp_signal, axis=1)\n",
    "# Normalize each component of each event by dividing by its maximum value\n",
    "normalized_phase_data = bp_signal / max_values_per_event[:, np.newaxis, :]\n",
    "print('-----------signal format convert finihs-------------------')\n",
    "print(bp_signal.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf3d279-f904-4bc6-bfb2-05dd20e543bc",
   "metadata": {},
   "source": [
    "## load pretrained models and network inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d7f4ea-1bf3-448f-9e2c-f5acec106eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.001  # Specify your learning rate\n",
    "\n",
    "# P_phase_model = load_model('./results/P_wave_phase_picking_10w_random_1006_256_100.h5')\n",
    "# S_phase_model = load_model('./results/S_wave_phase_picking_10w_random_1006_256_200.h5')\n",
    "\n",
    "# P_phase_output = P_phase_model.predict(normalized_phase_data)\n",
    "# S_phase_output = S_phase_model.predict(normalized_phase_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85222cc2-27ae-45a6-adee-ddb74d3bc53a",
   "metadata": {},
   "source": [
    "## Define evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb4c37db-a3e3-4b40-b854-e53c4ad5e51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_picking(pred_array, label_array):\n",
    "    pred_indx_array = []\n",
    "    label_indx_array = []\n",
    "    for i in range (pred_array.shape[0]-1):\n",
    "        pred_indx = np.argmax(pred_array[i, :])\n",
    "        # label_indx = np.argmax(label_array[i, :])\n",
    "        label_indx = label_array[i]\n",
    "        pred_indx_array.append(pred_indx)\n",
    "        label_indx_array.append(label_indx)\n",
    "\n",
    "    pred_indx_array = np.array(pred_indx_array)\n",
    "    label_indx_array = np.array(label_indx_array)\n",
    "\n",
    "    # calculate the error index\n",
    "    err_indx_array = label_indx_array- pred_indx_array\n",
    "\n",
    "    return err_indx_array\n",
    "\n",
    "def cal_mae_std(input_array, m):\n",
    "    # from sample to seconds\n",
    "    input_array = input_array/100\n",
    "    # filter those outliers\n",
    "    input_array[(input_array > m) | (input_array < -m)] = 0\n",
    "\n",
    "    # calculate the evaluation metrics\n",
    "    mae = np.mean(np.abs(input_array - np.mean(input_array)))\n",
    "    std = np.std(input_array)\n",
    "\n",
    "    # calculate the precision of picking results (within ±1 s)\n",
    "    precision = (np.sum(np.abs(input_array) <= 1) / len(input_array)) * 100\n",
    "    \n",
    "    return input_array, mae, std, precision \n",
    "\n",
    "\n",
    "def plot_histogram(input_array, input_mae, input_std, input_color, input_name):\n",
    "    plt.hist(input_array, bins=30, color=f'{input_color}', edgecolor='black', alpha=0.7)  # Adjust bins, color, edgecolor, and transparency\n",
    "    plt.xlabel('Picking error (s)', fontsize=12, fontweight='bold')  # Add x-axis label with custom font size\n",
    "    plt.ylabel('Count', fontsize=12, fontweight='bold')  # Add y-axis label with custom font size\n",
    "    plt.text(0.2, 0.8, f'MAE={input_mae:.2f} s\\n$\\sigma$={input_std:.2f} s', fontsize=10, fontweight='bold', transform=plt.gcf().transFigure)\n",
    "    plt.xticks(fontsize=10, fontweight='bold')  # Set font size for x-axis ticks\n",
    "    plt.yticks(fontsize=10, fontweight='bold')  # Set font size for y-axis ticks\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.5)  # Add grid lines with custom style and transparency\n",
    "    plt.legend([f'{input_name}'], prop={'weight': 'bold'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e0d643-0167-4ebf-998c-6f195bd64690",
   "metadata": {},
   "source": [
    "## Load the metrics predicted by EQCCT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6122e11-fcde-445a-a482-824720f8a494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of P-wave picking:14838\n",
      "Shape of S-wave picking:14783\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file (Please change the path to the output of EQCCT)\n",
    "df_p = pd.read_csv('./test_pwave_retrain_outputs/X_test_results.csv')\n",
    "df_s = pd.read_csv('./test_swave_retrain_outputs/X_test_results.csv')\n",
    "\n",
    "# Filter out rows where 'P_error' is NaN\n",
    "filtered_df_p = df_p[df_p['P_error'].notna()]\n",
    "filtered_df_s = df_s[df_s['s_error'].notna()]\n",
    "\n",
    "# Convert the 'P_error' column to a NumPy array\n",
    "EQCCT_P_error_indx = filtered_df_p['P_error'].to_numpy()\n",
    "EQCCT_S_error_indx = filtered_df_s['s_error'].to_numpy()\n",
    "\n",
    "print(f'Shape of P-wave picking:{EQCCT_P_error_indx.shape[0]}\\nShape of S-wave picking:{EQCCT_S_error_indx.shape[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0be712e-f374-4406-b9f7-3f37bbe8c50d",
   "metadata": {},
   "source": [
    "## Caculate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81119807-1c15-4ffc-ab1f-72d792d1739e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P-wave MAE and sigma of proposed: 0.1903 s\t0.5096 s\n",
      "P-wave MAE and sigma of EQCCT   : 0.1636 s\t0.5678 s\n",
      "S-wave MAE and sigma of proposed: 0.2126 s\t0.4738 s\n",
      "S-wave MAE and sigma of EQCCT   : 0.2357 s\t0.5139 s\n",
      "P-wave precision of proposed: 94.99 %\tS-wave precision of proposed: 95.43 %\n",
      "P-wave precision of EQCCT: 94.34 %\tS-wave precision of EQCCT: 94.97 %\n"
     ]
    }
   ],
   "source": [
    "# calculate error array for each method\n",
    "# Proposed_P_error_indx = evaluate_picking(P_phase_output, P_phase_label)\n",
    "# Proposed_S_error_indx = evaluate_picking(S_phase_output, S_phase_label)\n",
    "Proposed_P_error_indx = np.load('./data/P_error_proposed_1.5w.npy')\n",
    "Proposed_S_error_indx = np.load('./data/S_error_proposed_1.5w.npy')\n",
    "\n",
    "# evalute the performance of each method\n",
    "xx = 4\n",
    "P_error_array_eqcct, mae_P_eqcct, std_P_eqcct, precision_P_eqcct = cal_mae_std(EQCCT_P_error_indx, xx)\n",
    "S_error_array_eqcct, mae_S_eqcct, std_S_eqcct, precision_S_eqcct = cal_mae_std(EQCCT_S_error_indx, xx)\n",
    "P_error_proposed, mae_P_proposed, std_P_proposed, precision_P_proposed = cal_mae_std(Proposed_P_error_indx, xx)\n",
    "S_error_proposed, mae_S_proposed, std_S_proposed, precision_S_proposed = cal_mae_std(Proposed_S_error_indx, xx)\n",
    "\n",
    "print(f'P-wave MAE and sigma of proposed: {mae_P_proposed:.4f} s\\t{std_P_proposed:.4f} s\\nP-wave MAE and sigma of EQCCT   : {mae_P_eqcct:.4f} s\\t{std_P_eqcct:.4f} s')\n",
    "print(f'S-wave MAE and sigma of proposed: {mae_S_proposed:.4f} s\\t{std_S_proposed:.4f} s\\nS-wave MAE and sigma of EQCCT   : {mae_S_eqcct:.4f} s\\t{std_S_eqcct:.4f} s')\n",
    "print(f'P-wave precision of proposed: {precision_P_proposed:.2f} %\\tS-wave precision of proposed: {precision_S_proposed:.2f} %')\n",
    "print(f'P-wave precision of EQCCT: {precision_P_eqcct:.2f} %\\tS-wave precision of EQCCT: {precision_S_eqcct:.2f} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a7828-cc1c-4240-bbae-6b4e24e55cc7",
   "metadata": {},
   "source": [
    "## Compare the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba5b07f8-16b6-4a58-9600-1fe771a472b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))  # Set figure size\n",
    "ax = plt.subplot(221)\n",
    "plt.hist(P_error_array_eqcct, bins=30, color='palegoldenrod', edgecolor='black', alpha=0.7)  # Adjust bins, color, edgecolor, and transparency\n",
    "plt.xlabel('Picking error (s)', fontsize=12, fontweight='bold')  # Add x-axis label with custom font size\n",
    "plt.ylabel('Count', fontsize=12, fontweight='bold')  # Add y-axis label with custom font size\n",
    "plt.xticks(fontsize=10, fontweight='bold')  # Set font size for x-axis ticks\n",
    "plt.yticks(fontsize=10, fontweight='bold')  # Set font size for y-axis ticks\n",
    "plt.text(0.2, 0.8, f'MAE={mae_P_eqcct:.2f} s\\n$\\sigma$={std_P_eqcct:.2f} s', fontsize=10, fontweight='bold', ha='center', va='center', transform=ax.transAxes)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)  # Add grid lines with custom style and transparency\n",
    "plt.legend(['EQCCT (P)'], prop={'weight': 'bold'})\n",
    "\n",
    "ax = plt.subplot(222)\n",
    "plt.hist(P_error_proposed, bins=30, color='skyblue', edgecolor='black', alpha=0.7)  # Adjust bins, color, edgecolor, and transparency\n",
    "plt.xlabel('Picking error (s)', fontsize=12, fontweight='bold')  # Add x-axis label with custom font size\n",
    "plt.ylabel('Count', fontsize=12, fontweight='bold')  # Add y-axis label with custom font size\n",
    "plt.xticks(fontsize=10, fontweight='bold')  # Set font size for x-axis ticks\n",
    "plt.yticks(fontsize=10, fontweight='bold')  # Set font size for y-axis ticks\n",
    "plt.text(0.2, 0.8, f'MAE={mae_P_proposed:.2f} s\\n$\\sigma$={std_P_proposed:.2f} s', fontsize=10, fontweight='bold', ha='center', va='center', transform=ax.transAxes)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)  # Add grid lines with custom style and transparency\n",
    "plt.legend(['Proposed (P)'], prop={'weight': 'bold'})\n",
    "\n",
    "\n",
    "ax = plt.subplot(223)\n",
    "plt.hist(S_error_array_eqcct, bins=30, color='palegoldenrod', edgecolor='black', alpha=0.7)  # Adjust bins, color, edgecolor, and transparency\n",
    "plt.xlabel('Picking error (s)', fontsize=12, fontweight='bold')  # Add x-axis label with custom font size\n",
    "plt.ylabel('Count', fontsize=12, fontweight='bold')  # Add y-axis label with custom font size\n",
    "plt.xticks(fontsize=10, fontweight='bold')  # Set font size for x-axis ticks\n",
    "plt.yticks(fontsize=10, fontweight='bold')  # Set font size for y-axis ticks\n",
    "plt.text(0.2, 0.8, f'MAE={mae_S_eqcct:.2f} s\\n$\\sigma$={std_S_eqcct:.2f} s', fontsize=10, fontweight='bold', ha='center', va='center', transform=ax.transAxes)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)  # Add grid lines with custom style and transparency\n",
    "plt.legend(['EQCCT (S)'], prop={'weight': 'bold'})\n",
    "\n",
    "ax = plt.subplot(224)\n",
    "plt.hist(S_error_proposed, bins=30, color='skyblue', edgecolor='black', alpha=0.7)  # Adjust bins, color, edgecolor, and transparency\n",
    "plt.xlabel('Picking error (s)', fontsize=12, fontweight='bold')  # Add x-axis label with custom font size\n",
    "plt.ylabel('Count', fontsize=12, fontweight='bold')  # Add y-axis label with custom font size\n",
    "plt.xticks(fontsize=10, fontweight='bold')  # Set font size for x-axis ticks\n",
    "plt.yticks(fontsize=10, fontweight='bold')  # Set font size for y-axis ticks\n",
    "plt.text(0.2, 0.8, f'MAE={mae_S_proposed:.2f} s\\n$\\sigma$={std_S_proposed:.2f} s', fontsize=10, fontweight='bold', ha='center', va='center', transform=ax.transAxes)\n",
    "# plt.text(0.2, 0.8, f'MAE={mae_S_proposed:.2f} s\\n$\\sigma$={std_S_proposed:.2f} s', fontsize=10, fontweight='bold', transform=plt.gcf().transFigure)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.5)  # Add grid lines with custom style and transparency\n",
    "plt.legend(['Proposed (S)'], prop={'weight': 'bold'})\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'Retrained_EQCCT_vs_proposed.pdf', bbox_inches=\"tight\", dpi=150)\n",
    "plt.savefig(f'Retrained_EQCCT_vs_proposed.png', bbox_inches=\"tight\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523b2275-368c-4b04-a1cb-93d2ddac5416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fea8c8d-7d85-4099-a338-15bc733cfc5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9ab24e-9003-498f-8e95-2cbdcffae5e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
