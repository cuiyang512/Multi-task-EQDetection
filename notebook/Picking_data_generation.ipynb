{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99c504ec-788e-4cb9-8643-e38250bdf8d0",
   "metadata": {},
   "source": [
    "## Generate a large amount of training data for picking net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "797b85a4-25eb-4a23-9134-a29ab31349a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-16 16:04:09.294877: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-11-16 16:04:09.294907: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-11-16 16:04:09.295782: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-16 16:04:09.300324: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-11-16 16:04:09.813340: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import liblrary\n",
    "import numpy as np\n",
    "import h5py\n",
    "import random\n",
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../')\n",
    "from demos.utils import *\n",
    "\n",
    "# Make a new dir to save the picking error\n",
    "directory_path = \"../train_data_picking/\"\n",
    "\n",
    "# Create the directory, including any necessary parent directories\n",
    "os.makedirs(directory_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94be9de9-1383-49b2-a0df-98598f06e896",
   "metadata": {},
   "source": [
    "## Data path and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1238ff9-e12d-4f78-a74e-69796af2b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path\n",
    "signal_id_path = '../data/signalid_random_10w.npy'\n",
    "TXED_path = os.getenv('HOME')+'/Yang/Data/Earthquake_data/TXED/TXED_0913.h5' # Here, you may need to change the path of TXED\n",
    "out_path = '../train_data_picking'\n",
    "\n",
    "# load\n",
    "Dection_signal_id = np.load(signal_id_path, 'r')\n",
    "f_txed = h5py.File(TXED_path, 'r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d368f798-c49d-4e4e-9d6e-97dae8e0e788",
   "metadata": {},
   "source": [
    "## Generate arrivals, obtain waveforms, and build labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e8b6ba9-425a-4abd-83b9-eae23e543df3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------arrival time calculation begin-------------------\n",
      "-----------arrival time calculation end-------------------\n",
      "shape of arrivals: (100000,)\n",
      "-----------signal format convert begin-------------------\n",
      "-----------signal format convert finish-------------------\n",
      "(100000, 6000, 3)\n",
      "Processed_num: 0\t P_arrival_time: 99\t S_arrival_time: 616\t sample_num: 6000\n",
      "Processed_num: 5000\t P_arrival_time: 598\t S_arrival_time: 741\t sample_num: 6000\n",
      "Processed_num: 10000\t P_arrival_time: 98\t S_arrival_time: 328\t sample_num: 6000\n",
      "Processed_num: 15000\t P_arrival_time: 99\t S_arrival_time: 1267\t sample_num: 6000\n",
      "Processed_num: 20000\t P_arrival_time: 298\t S_arrival_time: 1749\t sample_num: 6000\n",
      "Processed_num: 25000\t P_arrival_time: 299\t S_arrival_time: 940\t sample_num: 6000\n",
      "Processed_num: 30000\t P_arrival_time: 898\t S_arrival_time: 1214\t sample_num: 6000\n",
      "Processed_num: 35000\t P_arrival_time: 699\t S_arrival_time: 1360\t sample_num: 6000\n",
      "Processed_num: 40000\t P_arrival_time: 598\t S_arrival_time: 1061\t sample_num: 6000\n",
      "Processed_num: 45000\t P_arrival_time: 198\t S_arrival_time: 944\t sample_num: 6000\n",
      "Processed_num: 50000\t P_arrival_time: 598\t S_arrival_time: 3350\t sample_num: 6000\n",
      "Processed_num: 55000\t P_arrival_time: 898\t S_arrival_time: 1524\t sample_num: 6000\n",
      "Processed_num: 60000\t P_arrival_time: 98\t S_arrival_time: 1184\t sample_num: 6000\n",
      "Processed_num: 65000\t P_arrival_time: 698\t S_arrival_time: 758\t sample_num: 6000\n",
      "Processed_num: 70000\t P_arrival_time: 698\t S_arrival_time: 795\t sample_num: 6000\n",
      "Processed_num: 75000\t P_arrival_time: 698\t S_arrival_time: 2248\t sample_num: 6000\n",
      "Processed_num: 80000\t P_arrival_time: 799\t S_arrival_time: 2167\t sample_num: 6000\n",
      "Processed_num: 85000\t P_arrival_time: 199\t S_arrival_time: 2693\t sample_num: 6000\n",
      "Processed_num: 90000\t P_arrival_time: 798\t S_arrival_time: 3199\t sample_num: 6000\n",
      "Processed_num: 95000\t P_arrival_time: 699\t S_arrival_time: 1025\t sample_num: 6000\n"
     ]
    }
   ],
   "source": [
    "# obtain the P- and S-wave arrivals\n",
    "P_arrival_list = []\n",
    "S_arrival_list = []\n",
    "print('-----------arrival time calculation begin-------------------')\n",
    "for key in Dection_signal_id:\n",
    "    if key in f_txed:   \n",
    "        dataset = f_txed.get(key)\n",
    "        P_arrival_list.append(int(dataset.attrs['p_arrival_sample']))\n",
    "        S_arrival_list.append(int(dataset.attrs['s_arrival_sample']))\n",
    "P_arrival_list = np.array(P_arrival_list)\n",
    "S_arrival_list = np.array(S_arrival_list)\n",
    "P_phase_label_indx = P_arrival_list\n",
    "S_phase_label_indx = S_arrival_list\n",
    "P_phase_label_indx = np.reshape(P_phase_label_indx, [P_phase_label_indx.shape[0], 1])\n",
    "S_phase_label_indx = np.reshape(S_phase_label_indx, [S_phase_label_indx.shape[0], 1])\n",
    "phase_label_indx = np.concatenate([P_phase_label_indx, S_phase_label_indx], axis=-1)\n",
    "print('-----------arrival time calculation end-------------------')\n",
    "print(f'shape of arrivals: {P_arrival_list.shape}')\n",
    "\n",
    "\n",
    "# apply the bandpass and normalize to each waveform\n",
    "signal_list = []\n",
    "print('-----------signal format convert begin-------------------')\n",
    "for key in Dection_signal_id:\n",
    "    if key in f_txed:   \n",
    "        dataset = f_txed.get(key)\n",
    "        datas = dataset['data']\n",
    "        datas = np.array(datas)\n",
    "        datas_0 = butter_bandpass_filter_zi(datas[:,0], 1, 45, 100, order=3)\n",
    "        datas_1 = butter_bandpass_filter_zi(datas[:,1], 1, 45, 100, order=3)\n",
    "        datas_2 = butter_bandpass_filter_zi(datas[:,2], 1, 45, 100, order=3)\n",
    "        datas = np.vstack([datas_0, datas_1, datas_2])\n",
    "        signal_list.append(datas) \n",
    "signal_values = np.array(signal_list)\n",
    "bp_signal= np.transpose(signal_values, [0, 2, 1])\n",
    "\n",
    "\n",
    "#Normalized trace-by-trace\n",
    "max_values_per_event = np.max(bp_signal, axis=1)\n",
    "# Normalize each component of each event by dividing by its maximum value\n",
    "normalized_phase_data = bp_signal / max_values_per_event[:, np.newaxis, :]\n",
    "print('-----------signal format convert finish-------------------')\n",
    "print(bp_signal.shape)\n",
    "\n",
    "p_wave_label = []\n",
    "s_wave_label = []\n",
    "for i in range (normalized_phase_data.shape[0]):\n",
    "    # Example usage:\n",
    "    p_indx = P_arrival_list[i]  # Arrival time of P-wave (in seconds)\n",
    "    s_indx = S_arrival_list[i]  # Arrival time of S-wave (in seconds)    \n",
    "    sample_num = 6000  # Sampling rate of seismic signal (in Hz)\n",
    "    #print(f'Processed_num:{i}\\t P_arrival_time: {p_indx}\\t S_arrival_time: {s_indx}\\t sample_num: {sample_num}')\n",
    "    if i % 5000 == 0:\n",
    "        print(f'Processed_num: {i}\\t P_arrival_time: {p_indx}\\t S_arrival_time: {s_indx}\\t sample_num: {sample_num}')\n",
    "    \n",
    "    # Generate labels for P-wave and S-wave first arrival picking\n",
    "    p_labels, s_labels = generate_first_arrival_labels(p_indx, s_indx, sample_num)\n",
    "    p_wave_label.append(p_labels)  \n",
    "    s_wave_label.append(s_labels)\n",
    "p_wave_label = np.array(p_wave_label)\n",
    "s_wave_label = np.array(s_wave_label)\n",
    "phase_label = np.concatenate([np.reshape(p_wave_label, [p_wave_label.shape[0], p_wave_label.shape[1], 1]), \\\n",
    "                              np.reshape(s_wave_label, [s_wave_label.shape[0], s_wave_label.shape[1], 1])], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe0e5c3a-0206-4274-b493-c8aa3c9acdc0",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44682804-9d1d-4e05-90dc-73ba6baa5867",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(f'{out_path}EQ_detection_phase_label.npy', phase_label)\n",
    "np.save(f'{out_path}EQ_detection_waveforms.npy', normalized_phase_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec31ef4-5809-4ad2-9999-5806fd6a095e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
